{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkllAS-sSDtv",
        "outputId": "88218ad8-1728-46e4-a7df-df1968c764ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 구글드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 : 내장 데이터 사용. subset 인자에 all로 train, test 데이터 모두 가져오기\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "news_data = fetch_20newsgroups(subset='all', random_state=42)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data = fetch_20newsgroups(subset='train',\n",
        "                               remove=('headers','footers','quotes'),  # 기사의 일부분 제거(본문만 학습시키기 위함)\n",
        "                               random_state=12)\n",
        "X_train = train_data.data\n",
        "y_train = train_data.target\n",
        "\n",
        "test_data = fetch_20newsgroups(subset='test',\n",
        "                              remove=('headers','footers','quotes'),\n",
        "                              random_state=12)\n",
        "X_test = test_data.data\n",
        "y_test = test_data.target\n",
        "print(f\"학습 데이터 크기: {len(X_train)}\\n 테스트 데이터 크기: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvx6a208SXIX",
        "outputId": "9188388e-d55d-403b-a975-db5bf5a2b6b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 크기: 11314\n",
            " 테스트 데이터 크기: 7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터 feature Vectorizer : 단어 발생 빈도수에만 기반한 CountVectorizer를 사용\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "cnt_vect = CountVectorizer()\n",
        "\n",
        "# CountVecorizer도 한번 fit 하면 검증, 테스트 데이터에도 똑같은 것으로 해야함!\n",
        "# 다시 한 번 fit하게 되면 벡터화되는 feature 개수가 달라짐!\n",
        "X_train_vec = cnt_vect.fit_transform(X_train)\n",
        "X_test_vec = cnt_vect.transform(X_test)\n",
        "\n",
        "# 로지스틱 리그레션으로 모델링하기\n",
        "lr_clf = LogisticRegression(max_iter=500)\n",
        "lr_clf.fit(X_train_vec, y_train)\n",
        "y_pred = lr_clf.predict(X_test_vec)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"분류 정확도 : {acc : .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGPRcs5MS3VP",
        "outputId": "d6151904-cef1-4e15-9d64-72df0b7f7f62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분류 정확도 :  0.5968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터 feature Vectorizer : Tf-idf를 사용\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "tf_idf = TfidfVectorizer()\n",
        "\n",
        "X_train_tf = tf_idf.fit_transform(X_train)\n",
        "X_test_tf = tf_idf.transform(X_test)\n",
        "\n",
        "# 로지스틱 리그레션으로 모델링하기\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_tf, y_train)\n",
        "y_pred = lr_clf.predict(X_test_tf)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Tf-idf 벡터화 후 정확도 :{acc : .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2IBAMcmTmU3",
        "outputId": "c9ebff96-0fc5-405b-879c-5529f1f4519c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tf-idf 벡터화 후 정확도 : 0.6737\n"
          ]
        }
      ]
    }
  ]
}